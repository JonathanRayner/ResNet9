* Background
https://myrtle.ai/how-to-train-your-resnet-1-baseline/
https://github.com/davidcpage/cifar10-fast

Current best on dawn: https://dawn.cs.stanford.edu/benchmark/#cifar10-train-time

[[net_diagram.svg]]

Some network specifics here: https://github.com/davidcpage/cifar10-fast/blob/master/demo.ipynb

* Import modules, data

#+BEGIN_SRC emacs-lisp
;; activate virtual environment so we can use jupyter
(pyvenv-activate "~/.pyenv/versions/tensorflow_env")
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python :session j
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

print("TensorFlow executing eagerly: {}".format(tf.executing_eagerly()))
#+END_SRC

#+RESULTS:
: TensorFlow executing eagerly: True

Import cifar10

#+BEGIN_SRC jupyter-python :session j
cifar = tf.keras.datasets.cifar10
(train_images, train_labels), (test_images, test_labels) = cifar.load_data()
cifar_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

# Take the last 10000 images from the training set to form a validation set
train_labels = train_labels.squeeze()
validation_images = train_images[-10000:, :, :]
validation_labels = train_labels[-10000:]
train_images = train_images[:-10000, :, :]
train_labels = train_labels[:-10000]

plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid('off')
    img_index = np.random.randint(0, 40000)
    plt.imshow(train_images[img_index])
    plt.xlabel(cifar_labels[train_labels[img_index]])
#+END_SRC

#+RESULTS:
[[file:./.ob-jupyter/52cd1d064b49d06513c106f7080d6424e6ab7602.png]]

Build some blocks for the ResNet

#+BEGIN_SRC jupyter-python :session j
class Conv2DBatchNormReLU(tf.keras.layers.Layer):
    """
    Creates a layer of the form:

    Convolutional layer 2D -> Batch Norm -> ReLU

    Conv layer uses He Uniform weight initialization.

Arguments:
    filters (int): number of filters used convolutions, and gives num channels of output tensor
    kernel_size (int or tuple of 2 integers): window size used in convolutions
    input_shape (tuple of 3 integers): only needed if this is the first layer in the network. Use (rows, cols, filters)

Output shape:
    (batch_size, rows, cols, filters)

Returns:
    A tensor of rank 4
    """

    def __init__(self, filters, kernel_size=3, **kwargs):
        super().__init__(**kwargs)
        self.conv2d = tf.keras.layers.Conv2D(filters=filters,
                                             kernel_size=kernel_size,
                                             padding='SAME',
                                             kernel_initializer=tf.keras.initializers.he_uniform())
        self.batch_norm = tf.keras.layers.BatchNormalization()
        self.relu = tf.keras.layers.ReLU()

    def call(self, inputs, training=False):
        x = self.conv2d(inputs)
        # Batch Norm disabled during inference
        x = self.batch_norm(x, training=training)
        x = self.relu(x)
        return x

class ResNet9Block(tf.keras.layers.Layer):
    """
    Creates a Residual Block of type used in the network in https://github.com/davidcpage/cifar10-fast (see demo.ipynbwhich details the structure). Structure:

    Let CBR = Convolutional layer 2D -> Batch Norm -> ReLU
    Let x = CBR -> Pooling Layer (factor of 2)

    Then the structure is (x -> CBR -> CBR) + x

    Arguments:
        filters (int): number of filters used in all convolutions, and gives num channels of output tensor
        kernel_size (int or tuple of 2 integers): window size used in all convolutions
    input_shape (tuple of 3 integers): only needed if this is the first layer in the network. Use (rows, cols, filters)

    Output shape:
        (batch_size, rows/2, cols/2, filters)

    Returns:
        A tensor of rank 4
    """

    def __init__(self, filters, kernel_size=3, **kwargs):
        super().__init__(**kwargs)
        self.conv_bn_relu_1 = Conv2DBatchNormReLU(filters=filters, kernel_size=kernel_size)
        self.conv_bn_relu_2 = Conv2DBatchNormReLU(filters=filters, kernel_size=kernel_size)
        self.conv_bn_relu_3 = Conv2DBatchNormReLU(filters=filters, kernel_size=kernel_size)
        self.max_pool2d = tf.keras.layers.MaxPool2D()

    def call(self, inputs):
        """
        Residual behaviour implemented here.
        """
        x = self.conv_bn_relu_1(inputs)
        x = self.max_pool2d(x)
        y = self.conv_bn_relu_2(x)
        y = self.conv_bn_relu_3(y)
        x = x + y
        return x
#+END_SRC

#+RESULTS:

Build the model (structure, sizes of filters, convolutional kernels, pooling sizes can be found at https://github.com/davidcpage/cifar10-fast/blob/master/demo.ipynb)

#+BEGIN_SRC jupyter-python :session j
model = tf.keras.models.Sequential([
    Conv2DBatchNormReLU(filters=64, input_shape=(32,32,3)),
    ResNet9Block(filters=128),
    Conv2DBatchNormReLU(filters=256),
    tf.keras.layers.MaxPool2D(2),
    ResNet9Block(filters=512),
    tf.keras.layers.MaxPool2D(4),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(10, use_bias=False)
])

# class ResNet9(tf.keras.Model):
#     """
#     ResNet9 architecture from https://github.com/davidcpage/cifar10-fast. Has 9 layers: Conv layer, Residual block containing 3 conv layers, Conv Layer, Residual block containing 3 conv layers, fully-connected layer for classification. Batch Norm is used after each convolutional layer, before ReLU. Max pooling is used once inside each residual block and explicitly. All convolutions use (3,3) window size, stride=1, no padding by default.
#     """

#     def __init__(self,
#                 num_classes=10,
#                 layer_filters=[64, 128, 256, 512],
#                 kernel_size=3,
#                 ,**kwargs):
#         super().__init__(**kwargs)
#         self.conv_1 = Conv2DBatchNormReLU(filters=layer_filters[0], kernel_size=kernel_size)
#         self.residual_block_1 = ResNet9Block(filters=layer_filters[1], kernel_size=kernel_size)
#         self.conv_2 = Conv2DBatchNormReLU(filters=layer_filters[2], kernel_size=kernel_size)
#         self.pooling_1 = tf.keras.layers.MaxPool2D(2)
#         self.residual_block_2 = ResNet9Block(filters=layer_filters[3], kernel_size=kernel_size)
#         self.pooling_2 = tf.keras.layers.MaxPool2D(4)
#         self.flatten = tf.keras.layers.Flatten()
#         self.fully_connected = tf.keras.layers.Dense(num_classes, use_bias=False)

#     def call(self, inputs):
#         x = self.conv_1(inputs)
#         x = self.residual_block_1(x)
#         x = self.conv_2(x)
#         x = self.pooling_1(x)
#         x = self.residual_block_2(x)
#         x = self.pooling_2(x)
#         x = self.flatten(x)
#         x = self.fully_connected(x)
#         return x

# model = ResNet9()
# model.build(input_shape=(None,32,32,3))

model.summary()

# TODO visualize (tried using functional API, but some more needed to get at residual blocks)
# tf.keras.utils.plot_model(
#     model, to_file='model.png', show_shapes=True, show_layer_names=True,
#     rankdir='TB', expand_nested=True
# )
#+END_SRC

#+RESULTS:
:RESULTS:
#+begin_example
Model: "sequential_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_batch_norm_re_lu_121  (None, 32, 32, 64)        2048      
_________________________________________________________________
res_net9block_29 (ResNet9Blo (None, 16, 16, 128)       370560    
_________________________________________________________________
conv2d_batch_norm_re_lu_125  (None, 16, 16, 256)       296192    
_________________________________________________________________
max_pooling2d_58 (MaxPooling (None, 8, 8, 256)         0         
_________________________________________________________________
res_net9block_30 (ResNet9Blo (None, 4, 4, 512)         5905920   
_________________________________________________________________
max_pooling2d_60 (MaxPooling (None, 1, 1, 512)         0         
_________________________________________________________________
flatten_14 (Flatten)         (None, 512)               0         
_________________________________________________________________
dense_14 (Dense)             (None, 10)                5120      
=================================================================
Total params: 6,579,840
Trainable params: 6,575,360
Non-trainable params: 4,480
_________________________________________________________________
#+end_example
[[file:./.ob-jupyter/045b448a6b4d6271cab268b52c7dbe58fc04f259.png]]
:END:

Train

#+BEGIN_SRC jupyter-python :session j
batch_size = 128
num_epochs = 10  # The number of epochs (full passes through the data) to train for

# triangle shape learning rate
amplitude = 0.4
offset = 10e-5 # we don't want exactly 0.0 learning rate at beginning and end
# upside down, shifted, scaled absolute value
learning_rates = [-abs(i*2*amplitude/num_epochs - amplitude) + amplitude + offset for i in range(num_epochs)]
lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: learning_rates[epoch], verbose=1)

# Compiling the model adds a loss function, optimiser and metrics to track during training
model.compile(optimizer=tf.keras.optimizers.Adam(),
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# The fit function allows you to fit the compiled model to some training data
model_fit = model.fit(train_images,
                          train_labels,
                          batch_size=batch_size,
                          epochs=num_epochs,
                          callbacks=[lr_schedule],
                          validation_data=(validation_images, validation_labels)
)

print('Training complete')

def plot_loss(model_fit):
    plt.figure(figsize=(10,10))
    plt.plot(model_fit.epoch, model_fit.history['accuracy'], color='b', label='Train')
    plt.plot(model_fit.epoch, model_fit.history['val_accuracy'], color='g', label='Validation')
    plt.xlabel('Epoch')
    plt.legend()
    plt.show()

plot_loss(model_fit)
#+END_SRC

#+RESULTS:
: 
: Epoch 00001: LearningRateScheduler reducing learning rate to 0.0001.
: Epoch 1/10
:  18/313 [>.............................] - ETA: 11:53 - loss: 2.9852 - accuracy: 0.2539
