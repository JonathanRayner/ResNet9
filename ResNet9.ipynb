{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "ynwzGIAneBbb"
   },
   "source": [
    "### Visualise examples from the dataset\n",
    "Run the cell below multiple times to see various images. (They might look a bit blurry because we've blown up the small images.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "8nMTxCOjd9WW"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "  plt.subplot(5,5,i+1)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.grid('off')\n",
    "\n",
    "  img_index = np.random.randint(0, 40000)\n",
    "  plt.imshow(train_images[img_index])\n",
    "  plt.xlabel(cifar_labels[train_labels[img_index]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "nNMAg7s3W0gg"
   },
   "source": [
    "###Visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "AVAdjH6o13tQ"
   },
   "outputs": [],
   "source": [
    "metric_values = model.evaluate(x=test_images, y=test_labels)\n",
    "\n",
    "print('Final TEST performance')\n",
    "for metric_value, metric_name in zip(metric_values, model.metrics_names):\n",
    "  print('{}: {}'.format(metric_name, metric_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "UlrSyMQpoV9f"
   },
   "source": [
    "### Classifying examples\n",
    "We now use our trained model to classify a sample of 25 images from the test set. We pass these 25 images to the  ```model.predict``` function, which returns a [25, 10] dimensional matrix. The entry at position $(i, j)$ of this matrix contains the probability that image $i$ belongs to class $j$. We obtain the most-likely prediction using the ```np.argmax``` function which returns the index of the maximum entry along the columns. Finally, we plot the result with the prediction and prediction probability labelled underneath the image and true label on the side. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "BjzP384wm9OW"
   },
   "outputs": [],
   "source": [
    "img_indices = np.random.randint(0, len(test_images), size=[25])\n",
    "sample_test_images = test_images[img_indices]\n",
    "sample_test_labels = [cifar_labels[i] for i in test_labels[img_indices].squeeze()]\n",
    "\n",
    "predictions = model.predict(sample_test_images)\n",
    "max_prediction = np.argmax(predictions, axis=1)\n",
    "prediction_probs = np.max(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "Ol-f9SacnySQ"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i, (img, prediction, prob, true_label) in enumerate(\n",
    "    zip(sample_test_images, max_prediction, prediction_probs, sample_test_labels)):\n",
    "  plt.subplot(5,5,i+1)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.grid('off')\n",
    "\n",
    "  plt.imshow(img)\n",
    "  plt.xlabel('{} ({:0.3f})'.format(cifar_labels[prediction], prob))\n",
    "  plt.ylabel('{}'.format(true_label))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "-3bIU8BErhiJ"
   },
   "source": [
    "## Your Tasks\n",
    "1. [**ALL**] Experiment with the network architecture, try changing the numbers, types and sizes of layers, the sizes of filters, using different padding etc. How do these decisions affect the performance of the model? In particular, try building a *fully convolutinoal* network, with no (max-)pooling layers. \n",
    "2. [**ALL**] Add BATCH NORMALISATION ([Tensorflow documentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/BatchNormalization) and [research paper](http://proceedings.mlr.press/v37/ioffe15.pdf)) to improve the model's generalisation.\n",
    "3. [**ADVANCED**] Read about Residual networks ([original paper](https://arxiv.org/pdf/1512.03385.pdf), ) and add **shortcut connections** to the model architecture. Try to build a simple reusable \"residual block\" as a [Keras Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model). \n",
    "4. [**OPTIONAL**]. Visualise the filters of the convolutional layers using Matplotlib. **HINT**: You can retrieve a reference to an individual layer from the sequential Keras model by calling```model.get_layer(name)```, replacing \"name\" with the name of the layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "PsWVvU9nbBCz"
   },
   "source": [
    "# ResNet blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "54yngAoVvbjp"
   },
   "outputs": [],
   "source": [
    "# may need to update tensorflow_addons if using google collab\n",
    "!pip install --upgrade tensorflow_addons\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import tensorflow_addons as tfa\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)\n",
    "\n",
    "\n",
    "print(\"TensorFlow executing eagerly: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "R6l3HODHbigP"
   },
   "outputs": [],
   "source": [
    "class Conv2DBatchNormReLU(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Creates a layer of the form:\n",
    "\n",
    "    Convolutional layer 2D -> Batch Norm -> ReLU\n",
    "\n",
    "    Conv layer uses He Uniform weight initialization, no bias, padding=1. Batch Norm uses epsilon=1e-5, momentum=0.9 \n",
    "\n",
    "Arguments:\n",
    "    filters (int): number of filters used convolutions, and gives num channels of output tensor\n",
    "    kernel_size (int or tuple of 2 integers): window size used in convolutions\n",
    "    input_shape (tuple of 3 integers): only needed if this is the first layer in the network. Use (rows, cols, filters)\n",
    "\n",
    "Output shape:\n",
    "    (batch_size, rows, cols, filters)\n",
    "\n",
    "Returns:\n",
    "    A tensor of rank 4\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filters, kernel_size=3, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv2d = tf.keras.layers.Conv2D(filters=filters,\n",
    "                                             kernel_size=kernel_size,\n",
    "                                             padding='SAME',\n",
    "                                             use_bias=False,\n",
    "                                             kernel_initializer=tf.keras.initializers.he_normal()\n",
    ")\n",
    "        self.batch_norm = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum=0.9)\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "      \n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.conv2d(inputs)\n",
    "        # From documentation: training=False (in call - not in layer!) \n",
    "        # layer will normalize its inputs using the mean and variance of its \n",
    "        # moving statistics, learned during training\n",
    "        x = self.batch_norm(x, training=training)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class ResNet9Block(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Creates a Residual Block of type used in the network in https://github.com/davidcpage/cifar10-fast (see demo.ipynbwhich details the structure). Structure:\n",
    "\n",
    "    Let CBR = Convolutional layer 2D -> Batch Norm -> ReLU\n",
    "    Let x = CBR -> Pooling Layer (factor of 2)\n",
    "\n",
    "    Then the structure is (x -> CBR -> CBR) + x\n",
    "\n",
    "    Arguments:\n",
    "        filters (int): number of filters used in all convolutions, and gives num channels of output tensor\n",
    "        kernel_size (int or tuple of 2 integers): window size used in all convolutions\n",
    "    input_shape (tuple of 3 integers): only needed if this is the first layer in the network. Use (rows, cols, filters)\n",
    "\n",
    "    Output shape:\n",
    "        (batch_size, rows/2, cols/2, filters)\n",
    "\n",
    "    Returns:\n",
    "        A tensor of rank 4\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filters, kernel_size=3, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv_bn_relu_1 = Conv2DBatchNormReLU(filters=filters, kernel_size=kernel_size)\n",
    "        self.conv_bn_relu_2 = Conv2DBatchNormReLU(filters=filters, kernel_size=kernel_size)\n",
    "        self.conv_bn_relu_3 = Conv2DBatchNormReLU(filters=filters, kernel_size=kernel_size)\n",
    "        self.max_pool2d = tf.keras.layers.MaxPool2D()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Residual behaviour implemented here.\n",
    "        \"\"\"\n",
    "        x = self.conv_bn_relu_1(inputs)\n",
    "        x = self.max_pool2d(x)\n",
    "        y = self.conv_bn_relu_2(x)\n",
    "        y = self.conv_bn_relu_3(y)\n",
    "        x = x + y\n",
    "        return x\n",
    "\n",
    "class ScalarMultiply(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Layer to implement multiplication by a scalar.\n",
    "\n",
    "    Arguments:\n",
    "        scalar (float): scalar to multiply by.\n",
    "\n",
    "    Output shape:\n",
    "        (batch_size, rows, cols, filters)\n",
    "\n",
    "    Returns:\n",
    "        A tensor of rank 4\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scalar, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.scalar = tf.constant(scalar)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.math.scalar_mul(self.scalar, inputs)\n",
    "        return x\n",
    "\n",
    "class ResNet9BlockShort(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Creates a Residual Block of type used in the network in https://github.com/davidcpage/cifar10-fast (see demo.ipynbwhich details the structure). Structure:\n",
    "\n",
    "    Let CBR = Convolutional layer 2D -> Batch Norm -> ReLU\n",
    "\n",
    "    Then the structure is x -> CBR -> CBR + x\n",
    "\n",
    "    Arguments:\n",
    "        filters (int): number of filters used in all convolutions, and gives num channels of output tensor\n",
    "        kernel_size (int or tuple of 2 integers): window size used in all convolutions\n",
    "    input_shape (tuple of 3 integers): only needed if this is the first layer in the network. Use (rows, cols, filters)\n",
    "\n",
    "    Output shape:\n",
    "        (batch_size, rows, cols, filters)\n",
    "\n",
    "    Returns:\n",
    "        A tensor of rank 4\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filters, kernel_size=3, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv2d_1 = tf.keras.layers.Conv2D(filters=filters,\n",
    "                                             kernel_size=kernel_size,\n",
    "                                             padding='SAME',\n",
    "                                             use_bias=False,\n",
    "                                             activation='relu',\n",
    "                                             kernel_initializer=tf.keras.initializers.he_uniform(),\n",
    "                                             kernel_regularizer=tf.keras.regularizers.l2(1e-3)\n",
    ")\n",
    "        self.conv2d_2 = tf.keras.layers.Conv2D(filters=filters,\n",
    "                                             kernel_size=kernel_size,\n",
    "                                             padding='SAME',\n",
    "                                             activation='relu',\n",
    "                                             use_bias=False,\n",
    "                                             kernel_initializer=tf.keras.initializers.he_uniform(),\n",
    "                                             kernel_regularizer=tf.keras.regularizers.l2(1e-3)\n",
    ")\n",
    "        self.batch_norm_1 = tf.keras.layers.BatchNormalization(epsilon=1.0e-5, momentum=0.9)\n",
    "        self.batch_norm_2 = tf.keras.layers.BatchNormalization(epsilon=1.0e-5, momentum=0.9)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Residual behaviour implemented here.\n",
    "        \"\"\"\n",
    "        x = self.conv2d_1(inputs)\n",
    "        x = self.batch_norm_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.batch_norm_2(x)\n",
    "        x = x + inputs\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "HS_D41ozqtJq"
   },
   "source": [
    "# Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "Pvy8JsWLqwV_"
   },
   "outputs": [],
   "source": [
    "class NormalizeZscore:\n",
    "    \"\"\"\n",
    "    Normalize numpy array of images by z-score, independently for each channel.\n",
    "    Note: converts to float32 and not the default of float 64.\n",
    "\n",
    "    Attributes:\n",
    "        self.means (numpy array) = list of means, calculated across dataset. one mean per channel\n",
    "        self.stds (numpy array) = list of stds, calculated across dataset. one std per channel\n",
    "    \n",
    "    Methods:\n",
    "        self.fit = calculate means and stds of train dataset and store as class attribute\n",
    "        self.transform = normalize dataset by z-score\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.means = None\n",
    "        self.stds = None\n",
    "\n",
    "    def fit(self, train_dataset):\n",
    "        self.means = np.mean(train_dataset, axis=(0,1,2))#, dtype=np.float32)\n",
    "        self.stds = np.std(train_dataset, axis=(0,1,2))#, dtype=np.float32)\n",
    "        return None\n",
    "\n",
    "    def transform(self, dataset):\n",
    "        dataset = (dataset - self.means)/self.stds\n",
    "        return dataset\n",
    "\n",
    "def flip(images):\n",
    "    \"\"\"\n",
    "    Use on 3D image (height, width, channels) or 4D (batch_size, height, width, channels)\n",
    "    \"\"\"\n",
    "    images = tf.image.random_flip_left_right(images)\n",
    "    return images\n",
    "\n",
    "# TODO investigate speed of just using tf function for shifts, padding often expensive\n",
    "def pad_and_crop(images):\n",
    "    \"\"\"\n",
    "    Use on 4D image (height, width, channels) \n",
    "    \"\"\"\n",
    "    original_shape = tf.shape(images)\n",
    "    # pad 4 pixels above, below, left right\n",
    "    paddings = tf.constant([[0, 0], [4, 4], [4, 4], [0, 0]])\n",
    "    images = tf.pad(images, paddings=paddings, mode=\"REFLECT\")\n",
    "    images = tf.image.random_crop(images, size=original_shape)\n",
    "    return images\n",
    "  \n",
    "def cutout(images, cutout_dim=[8,8]):\n",
    "    '''\n",
    "    Takes a 4D variable, channels last. Needs package tensorflow_addons\n",
    "\n",
    "    Args:\n",
    "        cutout_dim (list of integers): [height, width]\n",
    "    '''\n",
    "    images = tfa.image.random_cutout(images, mask_size = tf.constant(cutout_dim))\n",
    "    return images\n",
    "\n",
    "@tf.function # TODO check if decorating here improves performance\n",
    "def augment(images, labels):\n",
    "    \"\"\"\n",
    "    Apply random LR flip, pad with 4 pixels, then crop to 32x32, then apply 8x8 cutout.\n",
    "    Use on 4D image (batch_size, height, width, channels) \n",
    "    Use on datasets create with images paired with labels ie.\n",
    "\n",
    "    dataset = tf.from_tensor_slices((images, labels))\n",
    "    \"\"\"\n",
    "    images = pad_and_crop(images)\n",
    "    images = flip(images)\n",
    "    images = cutout(images)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "xYklIhisDEal"
   },
   "source": [
    "# Check Augmentation worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "OIZVvA3DDJMP"
   },
   "outputs": [],
   "source": [
    "# modified from https://www.wouterbulten.nl/blog/tech/data-augmentation-using-tensorflow-data-dataset/\n",
    "def plot_augmented_images(dataset, n_images, samples_per_image):\n",
    "    \"\"\"\n",
    "    Checks what repeated calls to the dataset do by plotting a grid of images.\n",
    "\n",
    "    1. If not using .batch already in the dataset, need to modify the iterator here\n",
    "    by writing \n",
    "    \n",
    "    for images in dataset.repeat(samples_per_image).batch(n_images):\n",
    "\n",
    "    2. If .batch is already being used as a method on the dataset, then this is the number of images\n",
    "    that will be displayed and\n",
    "\n",
    "    for images in dataset.repeat(samples_per_image):\n",
    "    \n",
    "    should be used. The correct n_images=batch_size also needs to be passed as \n",
    "    argument to the function in this second case.\n",
    "    \"\"\"\n",
    "    # initialize output array\n",
    "    output = np.zeros((32*n_images, 32*samples_per_image, 3))\n",
    "\n",
    "    row = 0\n",
    "    for images, labels in dataset.repeat(samples_per_image): #.batch(n_images):\n",
    "        # replace row in output array with several transforms of the image\n",
    "        output[:, row*32:(row+1)*32, :] = np.vstack(images.numpy())\n",
    "        row += 1\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(output)\n",
    "    plt.show()\n",
    "\n",
    "# get data and test augmentation\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# visualize augmentation on a few images\n",
    "n_images = 8\n",
    "\n",
    "# need to convert to float32 from int8 and normalize to visualize augmentation\n",
    "train_sample = (train_images[0:n_images]/255).astype(np.float32)\n",
    "train_sample_labels = train_labels[0:n_images]\n",
    "\n",
    "# convert to tensorflow datasets and apply pad, crop, cutout via .map(augment, ..)\n",
    "train_sample_dataset = tf.data.Dataset.from_tensor_slices((train_sample, train_sample_labels))\n",
    "\n",
    "augmented_train_sample_dataset = (train_sample_dataset\n",
    "                                  .batch(n_images)\n",
    "                                  .map(augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "                                  )\n",
    "\n",
    "plot_augmented_images(augmented_train_sample_dataset, n_images=n_images, samples_per_image=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "3DoxYtXXo1Om"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "r3doHlJTo7Cj"
   },
   "outputs": [],
   "source": [
    "# Build the model (structure, sizes of filters, convolutional kernels, pooling sizes can be found at https://github.com/davidcpage/cifar10-fast/blob/master/demo.ipynb)\n",
    "\n",
    "# Their implementation multiplies logits by 0.125, decorate for speed improvements\n",
    "@tf.function\n",
    "def scalar_multiply(x):\n",
    "    return 0.125*x\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    Conv2DBatchNormReLU(filters=64, input_shape=(32,32,3)),\n",
    "    ResNet9Block(filters=128),\n",
    "    Conv2DBatchNormReLU(filters=256),\n",
    "    tf.keras.layers.MaxPool2D(2),\n",
    "    ResNet9Block(filters=512),\n",
    "    tf.keras.layers.MaxPool2D(4),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, use_bias=False, activation=scalar_multiply)#,\n",
    "    # multiply logits by 0.125\n",
    "    #ScalarMultiply(scalar=0.125)\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "batch_size = 512\n",
    "num_epochs = 24\n",
    "warmup_epochs = 5\n",
    "max_learning_rate = 0.4\n",
    "\n",
    "# learning rate initially linearly increases, then decreases linearly\n",
    "learning_rates = list(np.linspace(0.08, max_learning_rate, warmup_epochs-1, endpoint=False)) \n",
    "learning_rates += list(np.linspace(max_learning_rate, 0.0, num_epochs-warmup_epochs+1, endpoint=False))\n",
    "#learning_rates += list(np.linspace(0.002, 0.0, 6, endpoint=False))\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: learning_rates[epoch], verbose=1)\n",
    "\n",
    "# Needs package tensorflow_addons for SGDW\n",
    "# Compiling the model adds a loss function, optimiser and metrics to track during training\n",
    "model.compile(tfa.optimizers.SGDW(learning_rate=1e-3, momentum=0.9, nesterov=True, weight_decay=5e-4),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# get data\n",
    "(train, train_labels), (test, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "cifar_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Take the last 10000 images from the training set to form a validation set\n",
    "train_labels = train_labels.squeeze()\n",
    "validation = train[-10000:, :, :]\n",
    "validation_labels = train_labels[-10000:]\n",
    "train = train[:-10000, :, :]\n",
    "train_labels = train_labels[:-10000]\n",
    "\n",
    "# normalize by z-score, fitting parameters from train\n",
    "zscore = NormalizeZscore()\n",
    "zscore.fit(train)\n",
    "train = zscore.transform(train)\n",
    "validation = zscore.transform(validation)\n",
    "test = zscore.transform(test)\n",
    "\n",
    "# create datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train, train_labels))\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((validation, validation_labels)) \n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test, test_labels)) \n",
    "\n",
    "# augment\n",
    "train_dataset = (train_dataset\n",
    "                 .cache()\n",
    "                 .repeat()  # keep augmenting on the fly\n",
    "                 .shuffle(40000, reshuffle_each_iteration=True)  # may want to change this\n",
    "                 .batch(batch_size)\n",
    "                 .map(augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "                 .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "                  )\n",
    "\n",
    "# no augmentation on validation and test\n",
    "validation_dataset = (validation_dataset\n",
    "                      .cache()\n",
    "                      .batch(batch_size)\n",
    "                      .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "                      )\n",
    "test_dataset = (test_dataset\n",
    "                      .cache()\n",
    "                      .batch(batch_size)\n",
    "                      .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "                      )\n",
    "\n",
    "# train\n",
    "model_fit = model.fit(train_dataset,\n",
    "                          epochs=num_epochs,\n",
    "                          steps_per_epoch=40000//batch_size,\n",
    "                          callbacks=[lr_schedule],\n",
    "                          validation_data=validation_dataset\n",
    ")\n",
    "\n",
    "print('Training complete')\n",
    "\n",
    "def plot_loss(model_fit):\n",
    "    figure, axes = plt.subplots(1, 3, figsize=(30,10)) \n",
    "    for i, metric in enumerate(['loss', 'accuracy']):\n",
    "        axes[2*i].plot(model_fit.epoch, model_fit.history[metric], color='b', label='Train')\n",
    "        axes[2*i].plot(model_fit.epoch, model_fit.history['val_'+metric], color='g', label='Validation')\n",
    "        axes[2*i].set(xlabel='Epoch', ylabel=metric)\n",
    "        axes[2*i].legend()\n",
    "    axes[1].plot(model_fit.epoch, np.log(model_fit.history['loss']), color='b', label='Train')\n",
    "    axes[1].plot(model_fit.epoch, np.log(model_fit.history['val_loss']), color='g', label='Validation')\n",
    "    axes[1].set(xlabel='Epoch', ylabel=\"Log loss\")\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(model_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "qDy7DsTiSBXp"
   },
   "source": [
    "## Using less custom layer grouping - runs the same speed as my implementation proving my implementation is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "hL4-0JpMSL-B"
   },
   "outputs": [],
   "source": [
    "cifar = tf.keras.datasets.cifar10\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar.load_data()\n",
    "cifar_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Take the last 10000 images from the training set to form a validation set\n",
    "train_labels = train_labels.squeeze()\n",
    "validation_images = train_images[-10000:, :, :]\n",
    "validation_labels = train_labels[-10000:]\n",
    "train_images = train_images[:-10000, :, :]\n",
    "train_labels = train_labels[:-10000]\n",
    "\n",
    "# Build the model (structure, sizes of filters, convolutional kernels, pooling sizes can be found at https://github.com/davidcpage/cifar10-fast/blob/master/demo.ipynb)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=64, input_shape=(32,32,3),\n",
    "                                            kernel_size=3,\n",
    "                                            padding='SAME',\n",
    "                                            activation='relu',\n",
    "                                            use_bias=False,\n",
    "                                            kernel_initializer=tf.keras.initializers.he_uniform(),\n",
    "                                            kernel_regularizer=tf.keras.regularizers.l2(1e-3)),\n",
    "        tf.keras.layers.BatchNormalization(epsilon=1.0e-5, momentum=0.9),\n",
    "        tf.keras.layers.Conv2D(filters=128, \n",
    "                                            kernel_size=3,\n",
    "                                            padding='SAME',\n",
    "                                            activation='relu',\n",
    "                                            use_bias=False,\n",
    "                                            kernel_initializer=tf.keras.initializers.he_uniform(),\n",
    "                                            kernel_regularizer=tf.keras.regularizers.l2(1e-3)),\n",
    "        tf.keras.layers.BatchNormalization(epsilon=1.0e-5, momentum=0.9),\n",
    "        tf.keras.layers.MaxPool2D(2),\n",
    "        ResNet9BlockShort(filters=128),\n",
    "        tf.keras.layers.Conv2D(filters=256, \n",
    "                                            kernel_size=3,\n",
    "                                            padding='SAME',\n",
    "                                            activation='relu',\n",
    "                                            use_bias=False,\n",
    "                                            kernel_initializer=tf.keras.initializers.he_uniform(),\n",
    "                                            kernel_regularizer=tf.keras.regularizers.l2(1e-3)),\n",
    "        tf.keras.layers.BatchNormalization(epsilon=1.0e-5, momentum=0.9),\n",
    "        tf.keras.layers.MaxPool2D(2),\n",
    "        tf.keras.layers.Conv2D(filters=512, \n",
    "                                            kernel_size=3,\n",
    "                                            padding='SAME',\n",
    "                                            activation='relu',\n",
    "                                            use_bias=False,\n",
    "                                            kernel_initializer=tf.keras.initializers.he_uniform(),\n",
    "                                            kernel_regularizer=tf.keras.regularizers.l2(1e-3)),\n",
    "        tf.keras.layers.BatchNormalization(epsilon=1.0e-5, momentum=0.9),\n",
    "        tf.keras.layers.MaxPool2D(2),\n",
    "        ResNet9BlockShort(filters=512),\n",
    "        tf.keras.layers.MaxPool2D(4),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(10, use_bias=False)\n",
    "        # Their implementation multiplies logits by 0.125\n",
    "        #tf.keras.layers.Multiply()\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# TODO visualize (tried using functional API, but some more needed to get at residual blocks)\n",
    "# tf.keras.utils.plot_model(\n",
    "#     model, to_file='model.png', show_shapes=True, show_layer_names=True,\n",
    "#     rankdir='TB', expand_nested=True\n",
    "# )\n",
    "\n",
    "batch_size = 512\n",
    "num_epochs = 35\n",
    "\n",
    "# triangle shape learning rate (abs upside-down, shifted, scaled)\n",
    "amplitude = 0.001 # decided by initial search, see below (default 0.001)\n",
    "offset = amplitude/10 # recommended to be 1/10 or 1/20 of amplitude\n",
    "warmup_epochs = 5 # increase learning rate for first few epochs\n",
    "last_epochs = 10 # use a very small learning rate over last few epochs\n",
    "\n",
    "def triangle_list(amplitude, epochs, offset):\n",
    "    return [-abs(i*2*amplitude/epochs - amplitude) + amplitude + offset for i in range(epochs)]\n",
    "\n",
    "# first train with triangular learning rate, then small learning rate for last few epochs\n",
    "#learning_rates = triangle_list(amplitude, triangle_epochs, offset) + list(np.linspace(offset, offset/100, num_epochs-triangle_epochs))\n",
    "#learning_rates = list(np.linspace(amplitude, offset, triangle_epochs)) + list(np.linspace(offset, offset/10, num_epochs-triangle_epochs))\n",
    "#learning_rates = [1e0]*3 + [1e-1]*7 + [1e-2]*10\n",
    "\n",
    "# from their github\n",
    "#learning_rates = list(np.linspace(0.08, 0.4, triangle_epochs, endpoint=False)) + list(np.linspace(0.4, 0.0, num_epochs-triangle_epochs+1, endpoint=False))\n",
    "\n",
    "# my version\n",
    "learning_rates = list(np.linspace(offset, amplitude, warmup_epochs, endpoint=False)) \n",
    "learning_rates += list(np.linspace(amplitude, offset/2, num_epochs-warmup_epochs-last_epochs-5, endpoint=True)) \n",
    "learning_rates += list(np.linspace(offset/2, offset/100, last_epochs, endpoint=True))\n",
    "learning_rates += list(np.linspace(1e-5, 1e-6, last_epochs, endpoint=True))\n",
    "\n",
    "\n",
    "#learning_rates = [i*10**j for j in range(-5,-1) for i in range(1,10,2)] # 20 epochs, search for max learning rate initially\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: learning_rates[epoch], verbose=1)\n",
    "\n",
    "# Compiling the model adds a loss function, optimiser and metrics to track during training\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# cutout from https://github.com/yu4u/cutout-random-erasing\n",
    "#get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3,\n",
    "#                  v_l=0, v_h=255, pixel_level=False)\n",
    "\n",
    "#    p : the probability that random erasing is performed\n",
    "#    s_l, s_h : minimum / maximum proportion of erased area against input image\n",
    "#    r_1, r_2 : minimum / maximum aspect ratio of erased area\n",
    "#    v_l, v_h : minimum / maximum value for erased area\n",
    "#    pixel_level : pixel-level randomization for erased area\n",
    "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
    "    def eraser(input_img):\n",
    "        img_h, img_w, img_c = input_img.shape\n",
    "        p_1 = np.random.rand()\n",
    "\n",
    "        if p_1 > p:\n",
    "            return input_img\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, img_w)\n",
    "            top = np.random.randint(0, img_h)\n",
    "\n",
    "            if left + w <= img_w and top + h <= img_h:\n",
    "                break\n",
    "\n",
    "        if pixel_level:\n",
    "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "        else:\n",
    "            c = np.random.uniform(v_l, v_h)\n",
    "\n",
    "        input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "        return input_img\n",
    "\n",
    "    return eraser\n",
    "\n",
    "# always apply cutout with pixel value 0, size 8x8 (8^2/32^2 = 0.0625 to use in their implementation)\n",
    "#eraser = get_random_eraser(p=1.0, s_l=0.0625, s_h=.0625, r_1=1.0, r_2=1.0, v_l=0, v_h=0)\n",
    "# using some erasing defaults (leads to random choices of width and height and size)\n",
    "eraser = get_random_eraser(p=0.8, s_h=0.0625)\n",
    "\n",
    "# Data preprocessing (z-score normalize) and augmentation (LR flip, TODO cutout)\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    horizontal_flip=True,\n",
    "    height_shift_range=8, # this means +- 4 pixels\n",
    "    width_shift_range=8,\n",
    "    preprocessing_function=eraser # cutout\n",
    "    )\n",
    "\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True)\n",
    "\n",
    "# compute quantities required for normalization based on train\n",
    "train_datagen.fit(train_images)\n",
    "test_datagen.fit(train_images)\n",
    "\n",
    "# train\n",
    "model_fit = model.fit(train_datagen.flow(train_images, train_labels, batch_size=batch_size),\n",
    "                          epochs=num_epochs,\n",
    "                          callbacks=[lr_schedule],\n",
    "                          validation_data=test_datagen.flow(validation_images, validation_labels)\n",
    ")\n",
    "\n",
    "print('Training complete')\n",
    "\n",
    "def plot_loss(model_fit):\n",
    "    figure, axes = plt.subplots(1, 3, figsize=(30,10)) \n",
    "    for i, metric in enumerate(['loss', 'accuracy']):\n",
    "        axes[2*i].plot(model_fit.epoch, model_fit.history[metric], color='b', label='Train')\n",
    "        axes[2*i].plot(model_fit.epoch, model_fit.history['val_'+metric], color='g', label='Validation')\n",
    "        axes[2*i].set(xlabel='Epoch', ylabel=metric)\n",
    "        axes[2*i].legend()\n",
    "    axes[1].plot(model_fit.epoch, np.log(model_fit.history['loss']), color='b', label='Train')\n",
    "    axes[1].plot(model_fit.epoch, np.log(model_fit.history['val_loss']), color='g', label='Validation')\n",
    "    axes[1].set(xlabel='Epoch', ylabel=\"Log loss\")\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(model_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "Z2b_urvnT_pE"
   },
   "source": [
    "# Timing their implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "1D_cqwv6Kdvb"
   },
   "outputs": [],
   "source": [
    "####################\n",
    "## CORE\n",
    "#####################\n",
    "\n",
    "import inspect\n",
    "from collections import namedtuple, defaultdict\n",
    "from functools import partial\n",
    "import functools\n",
    "from itertools import chain, count, islice as take\n",
    "\n",
    "#####################\n",
    "## dict utils\n",
    "#####################\n",
    "\n",
    "union = lambda *dicts: {k: v for d in dicts for (k, v) in d.items()}\n",
    "\n",
    "make_tuple = lambda path: (path,) if isinstance(path, str) else path\n",
    "\n",
    "def path_iter(nested_dict, pfx=()):\n",
    "    for name, val in nested_dict.items():\n",
    "        if isinstance(val, dict): yield from path_iter(val, pfx+make_tuple(name))\n",
    "        else: yield (pfx+make_tuple(name), val)  \n",
    "            \n",
    "map_values = lambda func, dct: {k: func(v) for k,v in dct.items()}\n",
    "\n",
    "def map_nested(func, nested_dict):\n",
    "    return {k: map_nested(func, v) if isinstance(v, dict) else func(v) for k,v in nested_dict.items()}\n",
    "\n",
    "def group_by_key(seq):\n",
    "    res = defaultdict(list)\n",
    "    for k, v in seq: \n",
    "        res[k].append(v) \n",
    "    return res\n",
    "\n",
    "reorder = lambda dct, keys: {k: dct[k] for k in keys}\n",
    "\n",
    "#####################\n",
    "## graph building\n",
    "#####################\n",
    "\n",
    "def identity(value): return value\n",
    "\n",
    "def build_graph(net, path_map='_'.join):\n",
    "    net = {path: node if len(node) is 3 else (*node, None) for path, node in path_iter(net)}\n",
    "    default_inputs = chain([('input',)], net.keys())\n",
    "    resolve_path = lambda path, pfx: pfx+path if (pfx+path in net or not pfx) else resolve_path(net, path, pfx[:-1])\n",
    "    return {path_map(path): (typ, value, ([path_map(default)] if inputs is None else [path_map(resolve_path(make_tuple(k), path[:-1])) for k in inputs])) \n",
    "            for (path, (typ, value, inputs)), default in zip(net.items(), default_inputs)}\n",
    "\n",
    "#####################\n",
    "## network visualisation (requires pydot)\n",
    "#####################\n",
    "import IPython.display\n",
    "\n",
    "class ColorMap(dict):\n",
    "    palette = (\n",
    "        'bebada,ffffb3,fb8072,8dd3c7,80b1d3,fdb462,b3de69,fccde5,bc80bd,ccebc5,ffed6f,1f78b4,33a02c,e31a1c,ff7f00,'\n",
    "        '4dddf8,e66493,b07b87,4e90e3,dea05e,d0c281,f0e189,e9e8b1,e0eb71,bbd2a4,6ed641,57eb9c,3ca4d4,92d5e7,b15928'\n",
    "    ).split(',')\n",
    " \n",
    "    def __missing__(self, key):\n",
    "        self[key] = self.palette[len(self) % len(self.palette)]\n",
    "        return self[key]\n",
    "\n",
    "def make_pydot(nodes, edges, direction='LR', sep='_', **kwargs):\n",
    "    from pydot import Dot, Cluster, Node, Edge\n",
    "    class Subgraphs(dict):\n",
    "        def __missing__(self, path):\n",
    "            *parent, label = path\n",
    "            subgraph = Cluster(sep.join(path), label=label, style='rounded, filled', fillcolor='#77777744')\n",
    "            self[tuple(parent)].add_subgraph(subgraph)\n",
    "            return subgraph\n",
    "    g = Dot(rankdir=direction, directed=True, **kwargs)\n",
    "    g.set_node_defaults(\n",
    "        shape='box', style='rounded, filled', fillcolor='#ffffff')\n",
    "    subgraphs = Subgraphs({(): g})\n",
    "    for path, attr in nodes:\n",
    "        *parent, label = path.split(sep)\n",
    "        subgraphs[tuple(parent)].add_node(\n",
    "            Node(name=path, label=label, **attr))\n",
    "    for src, dst, attr in edges:\n",
    "        g.add_edge(Edge(src, dst, **attr))\n",
    "    return g\n",
    "\n",
    "class DotGraph():\n",
    "    colors = ColorMap()   \n",
    "    def __init__(self, graph, size=15, direction='LR'):\n",
    "        self.nodes = [(k, {\n",
    "            'tooltip': '%s %.1000r' % (typ, value), \n",
    "            'fillcolor': '#'+self.colors[typ],\n",
    "        }) for k, (typ, value, inputs) in graph.items()] \n",
    "        self.edges = [(src, k, {}) for (k, (_,_,inputs)) in graph.items() for src in inputs]\n",
    "        self.size, self.direction = size, direction\n",
    "\n",
    "    def dot_graph(self, **kwargs):\n",
    "        return make_pydot(self.nodes, self.edges, size=self.size, \n",
    "                            direction=self.direction, **kwargs)\n",
    "\n",
    "    def svg(self, **kwargs):\n",
    "        return self.dot_graph(**kwargs).create(format='svg').decode('utf-8')\n",
    "\n",
    "    try:\n",
    "        import pydot\n",
    "        def _repr_svg_(self):\n",
    "            return self.svg()\n",
    "    except ImportError:\n",
    "        def __repr__(self):\n",
    "            return 'pydot is needed for network visualisation'\n",
    "\n",
    "\n",
    "#####################\n",
    "## Layers\n",
    "##################### \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from collections import namedtuple\n",
    "import copy\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cpu = torch.device('cpu')\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self, net, loss=None):\n",
    "        super().__init__()\n",
    "        self.graph = {path: (typ, typ(**params), inputs) for path, (typ, params, inputs) in build_graph(net).items()}\n",
    "        self.loss = loss or identity\n",
    "        for path, (_,node,_) in self.graph.items(): \n",
    "            setattr(self, path, node)\n",
    "    \n",
    "    def nodes(self):\n",
    "        return (node for _,node,_ in self.graph.values())\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        outputs = dict(inputs)\n",
    "        for k, (_, node, ins) in self.graph.items():\n",
    "            outputs[k] = node(*[outputs[x] for x in ins])\n",
    "        return outputs\n",
    "    \n",
    "    def half(self):\n",
    "        for node in self.nodes():\n",
    "            if isinstance(node, nn.Module) and not isinstance(node, nn.BatchNorm2d):\n",
    "                node.half()\n",
    "        return self\n",
    "\n",
    "build_model = lambda network, loss: Network(network, loss).half().to(device)\n",
    "show = lambda network, size=15: display(DotGraph(network.graph if isinstance(network, Network) else build_graph(network), size=size))\n",
    "    \n",
    "class Add(namedtuple('Add', [])):\n",
    "    def __call__(self, x, y): return x + y \n",
    "    \n",
    "class AddWeighted(namedtuple('AddWeighted', ['wx', 'wy'])):\n",
    "    def __call__(self, x, y): return self.wx*x + self.wy*y \n",
    "    \n",
    "class Identity(namedtuple('Identity', [])):\n",
    "    def __call__(self, x): return x\n",
    "\n",
    "class BatchNorm(nn.BatchNorm2d):\n",
    "    def __init__(self, num_features, eps=1e-05, momentum=0.1, weight=True, bias=True):\n",
    "        super().__init__(num_features, eps=eps, momentum=momentum)\n",
    "        self.weight.data.fill_(1.0)\n",
    "        self.bias.data.fill_(0.0)\n",
    "        self.weight.requires_grad = weight\n",
    "        self.bias.requires_grad = bias\n",
    "\n",
    "class GhostBatchNorm(BatchNorm):\n",
    "    def __init__(self, num_features, num_splits, **kw):\n",
    "        super().__init__(num_features, **kw)\n",
    "        self.num_splits = num_splits\n",
    "        self.register_buffer('running_mean', torch.zeros(num_features*self.num_splits))\n",
    "        self.register_buffer('running_var', torch.ones(num_features*self.num_splits))\n",
    "\n",
    "    def train(self, mode=True):\n",
    "        if (self.training is True) and (mode is False): #lazily collate stats when we are going to use them\n",
    "            self.running_mean = torch.mean(self.running_mean.view(self.num_splits, self.num_features), dim=0).repeat(self.num_splits)\n",
    "            self.running_var = torch.mean(self.running_var.view(self.num_splits, self.num_features), dim=0).repeat(self.num_splits)\n",
    "        return super().train(mode)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        N, C, H, W = input.shape\n",
    "        if self.training or not self.track_running_stats:\n",
    "            return F.batch_norm(\n",
    "                input.view(-1, C*self.num_splits, H, W), self.running_mean, self.running_var, \n",
    "                self.weight.repeat(self.num_splits), self.bias.repeat(self.num_splits),\n",
    "                True, self.momentum, self.eps).view(N, C, H, W) \n",
    "        else:\n",
    "            return F.batch_norm(\n",
    "                input, self.running_mean[:self.num_features], self.running_var[:self.num_features], \n",
    "                self.weight, self.bias, False, self.momentum, self.eps)\n",
    "        \n",
    "class Mul(nn.Module):\n",
    "    def __init__(self, weight):\n",
    "        super().__init__()\n",
    "        self.weight = weight\n",
    "    def __call__(self, x): \n",
    "        return x*self.weight\n",
    "    \n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): \n",
    "        return x.view(x.size(0), x.size(1))\n",
    "\n",
    "# Losses\n",
    "class CrossEntropyLoss(namedtuple('CrossEntropyLoss', [])):\n",
    "    def __call__(self, log_probs, target):\n",
    "        return torch.nn.functional.nll_loss(log_probs, target, reduction='none')\n",
    "    \n",
    "class KLLoss(namedtuple('KLLoss', [])):        \n",
    "    def __call__(self, log_probs):\n",
    "        return -log_probs.mean(dim=1)\n",
    "\n",
    "class Correct(namedtuple('Correct', [])):\n",
    "    def __call__(self, classifier, target):\n",
    "        return classifier.max(dim = 1)[1] == target\n",
    "\n",
    "class LogSoftmax(namedtuple('LogSoftmax', ['dim'])):\n",
    "    def __call__(self, x):\n",
    "        return torch.nn.functional.log_softmax(x, self.dim, _stacklevel=5)\n",
    "\n",
    "    \n",
    "# node definitions   \n",
    "from inspect import signature    \n",
    "empty_signature = inspect.Signature()\n",
    "\n",
    "class node_def(namedtuple('node_def', ['type'])):\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return (self.type, dict(signature(self.type).bind(*args, **kwargs).arguments))\n",
    "\n",
    "conv = node_def(nn.Conv2d)\n",
    "linear = node_def(nn.Linear)\n",
    "batch_norm = node_def(BatchNorm)\n",
    "pool = node_def(nn.MaxPool2d)\n",
    "relu = node_def(nn.ReLU)\n",
    "    \n",
    "def map_types(mapping, net):\n",
    "    def f(node):\n",
    "        typ, *rest = node\n",
    "        return (mapping.get(typ, typ), *rest)\n",
    "    return map_nested(f, net) \n",
    "\n",
    "#####################\n",
    "## Compat\n",
    "##################### \n",
    "\n",
    "def to_numpy(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.detach().cpu().numpy()  \n",
    "    return x\n",
    "  \n",
    "def flip_lr(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return torch.flip(x, [-1]) \n",
    "    return x[..., ::-1].copy()\n",
    "  \n",
    "trainable_params = lambda model: {k:p for k,p in model.named_parameters() if p.requires_grad}\n",
    "\n",
    "#####################\n",
    "## Optimisers\n",
    "##################### \n",
    "\n",
    "from functools import partial\n",
    "\n",
    "def nesterov_update(w, dw, v, lr, weight_decay, momentum):\n",
    "    dw.add_(weight_decay, w).mul_(-lr)\n",
    "    v.mul_(momentum).add_(dw)\n",
    "    w.add_(dw.add_(momentum, v))\n",
    "\n",
    "norm = lambda x: torch.norm(x.reshape(x.size(0),-1).float(), dim=1)[:,None,None,None]\n",
    "\n",
    "def LARS_update(w, dw, v, lr, weight_decay, momentum):\n",
    "    nesterov_update(w, dw, v, lr*(norm(w)/(norm(dw)+1e-2)).to(w.dtype), weight_decay, momentum)\n",
    "\n",
    "def zeros_like(weights):\n",
    "    return [torch.zeros_like(w) for w in weights]\n",
    "\n",
    "def optimiser(weights, param_schedule, update, state_init):\n",
    "    weights = list(weights)\n",
    "    return {'update': update, 'param_schedule': param_schedule, 'step_number': 0, 'weights': weights,  'opt_state': state_init(weights)}\n",
    "\n",
    "def opt_step(update, param_schedule, step_number, weights, opt_state):\n",
    "    step_number += 1\n",
    "    param_values = {k: f(step_number) for k, f in param_schedule.items()}\n",
    "    for w, v in zip(weights, opt_state):\n",
    "        if w.requires_grad:\n",
    "            update(w.data, w.grad.data, v, **param_values)\n",
    "    return {'update': update, 'param_schedule': param_schedule, 'step_number': step_number, 'weights': weights,  'opt_state': opt_state}\n",
    "\n",
    "LARS = partial(optimiser, update=LARS_update, state_init=zeros_like)\n",
    "SGD = partial(optimiser, update=nesterov_update, state_init=zeros_like)\n",
    "  \n",
    "class PiecewiseLinear(namedtuple('PiecewiseLinear', ('knots', 'vals'))):\n",
    "    def __call__(self, t):\n",
    "        return np.interp([t], self.knots, self.vals)[0]\n",
    "     \n",
    "class Const(namedtuple('Const', ['val'])):\n",
    "    def __call__(self, x):\n",
    "        return self.val\n",
    "\n",
    "#####################\n",
    "## DATA\n",
    "##################### \n",
    "\n",
    "import torchvision\n",
    "from functools import lru_cache as cache\n",
    "\n",
    "@cache(None)\n",
    "def cifar10(root='./data'):\n",
    "    download = lambda train: torchvision.datasets.CIFAR10(root=root, train=train, download=True)\n",
    "    return {k: {'data': torch.tensor(v.data), 'targets': torch.tensor(v.targets)} \n",
    "            for k,v in [('train', download(True)), ('valid', download(False))]}\n",
    "  \n",
    "cifar10_mean, cifar10_std = [\n",
    "    (125.31, 122.95, 113.87), # equals np.mean(cifar10()['train']['data'], axis=(0,1,2)) \n",
    "    (62.99, 62.09, 66.70), # equals np.std(cifar10()['train']['data'], axis=(0,1,2))\n",
    "]\n",
    "cifar10_classes= 'airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck'.split(', ')\n",
    "\n",
    "#####################\n",
    "## data preprocessing\n",
    "#####################\n",
    "mean, std = [torch.tensor(x, device=device, dtype=torch.float16) for x in (cifar10_mean, cifar10_std)]\n",
    "\n",
    "normalise = lambda data, mean=mean, std=std: (data - mean)/std\n",
    "unnormalise = lambda data, mean=mean, std=std: data*std + mean\n",
    "pad = lambda data, border: nn.ReflectionPad2d(border)(data)\n",
    "transpose = lambda x, source='NHWC', target='NCHW': x.permute([source.index(d) for d in target]) \n",
    "to = lambda *args, **kwargs: (lambda x: x.to(*args, **kwargs))\n",
    "\n",
    "def preprocess(dataset, transforms):\n",
    "    dataset = copy.copy(dataset)\n",
    "    for transform in reversed(transforms):\n",
    "        dataset['data'] = transform(dataset['data'])\n",
    "    return dataset\n",
    "\n",
    "#####################\n",
    "## Data augmentation\n",
    "#####################\n",
    "\n",
    "chunks = lambda data, splits: (data[start:end] for (start, end) in zip(splits, splits[1:]))\n",
    "\n",
    "even_splits = lambda N, num_chunks: np.cumsum([0] + [(N//num_chunks)+1]*(N % num_chunks)  + [N//num_chunks]*(num_chunks - (N % num_chunks)))\n",
    "\n",
    "def shuffled(xs, inplace=False):\n",
    "    xs = xs if inplace else copy.copy(xs) \n",
    "    np.random.shuffle(xs)\n",
    "    return xs\n",
    "\n",
    "def transformed(data, targets, transform, max_options=None, unshuffle=False):\n",
    "    i = torch.randperm(len(data), device=device)\n",
    "    data = data[i]\n",
    "    options = shuffled(transform.options(data.shape), inplace=True)[:max_options]\n",
    "    data = torch.cat([transform.apply(x, **choice) for choice, x in zip(options, chunks(data, even_splits(len(data), len(options))))])\n",
    "    return (data[torch.argsort(i)], targets) if unshuffle else (data, targets[i])\n",
    "\n",
    "class Batches():\n",
    "    def __init__(self, batch_size, transforms=(), dataset=None, shuffle=True, drop_last=False, max_options=None):\n",
    "        self.dataset, self.transforms, self.shuffle, self.max_options = dataset, transforms, shuffle, max_options\n",
    "        N = len(dataset['data'])\n",
    "        self.splits = list(range(0, N+1, batch_size))\n",
    "        if not drop_last and self.splits[-1] != N:\n",
    "            self.splits.append(N)\n",
    "     \n",
    "    def __iter__(self):\n",
    "        data, targets = self.dataset['data'], self.dataset['targets']\n",
    "        for transform in self.transforms:\n",
    "            data, targets = transformed(data, targets, transform, max_options=self.max_options, unshuffle=not self.shuffle)\n",
    "        if self.shuffle:\n",
    "            i = torch.randperm(len(data), device=device)\n",
    "            data, targets = data[i], targets[i]\n",
    "        return ({'input': x.clone(), 'target': y} for (x, y) in zip(chunks(data, self.splits), chunks(targets, self.splits)))\n",
    "    \n",
    "    def __len__(self): \n",
    "        return len(self.splits) - 1\n",
    "    \n",
    "#####################\n",
    "## Augmentations\n",
    "#####################\n",
    "\n",
    "class Crop(namedtuple('Crop', ('h', 'w'))):\n",
    "    def apply(self, x, x0, y0):\n",
    "        return x[..., y0:y0+self.h, x0:x0+self.w] \n",
    "\n",
    "    def options(self, shape):\n",
    "        *_, H, W = shape\n",
    "        return [{'x0': x0, 'y0': y0} for x0 in range(W+1-self.w) for y0 in range(H+1-self.h)]\n",
    "    \n",
    "class FlipLR(namedtuple('FlipLR', ())):\n",
    "    def apply(self, x, choice):\n",
    "        return flip_lr(x) if choice else x \n",
    "        \n",
    "    def options(self, shape):\n",
    "        return [{'choice': b} for b in [True, False]]\n",
    "\n",
    "class Cutout(namedtuple('Cutout', ('h', 'w'))):\n",
    "    def apply(self, x, x0, y0):\n",
    "        x[..., y0:y0+self.h, x0:x0+self.w] = 0.0\n",
    "        return x\n",
    "\n",
    "    def options(self, shape):\n",
    "        *_, H, W = shape\n",
    "        return [{'x0': x0, 'y0': y0} for x0 in range(W+1-self.w) for y0 in range(H+1-self.h)]  \n",
    "\n",
    "#####################\n",
    "## TRAINING\n",
    "#####################\n",
    "\n",
    "import time\n",
    "\n",
    "class Timer():\n",
    "    def __init__(self, synch=None):\n",
    "        self.synch = synch or (lambda: None)\n",
    "        self.synch()\n",
    "        self.times = [time.perf_counter()]\n",
    "        self.total_time = 0.0\n",
    "\n",
    "    def __call__(self, update_total=True):\n",
    "        self.synch()\n",
    "        self.times.append(time.perf_counter())\n",
    "        delta_t = self.times[-1] - self.times[-2]\n",
    "        if update_total:\n",
    "            self.total_time += delta_t\n",
    "        return delta_t\n",
    "\n",
    "default_table_formats = {float: '{:{w}.4f}', str: '{:>{w}s}', 'default': '{:{w}}', 'title': '{:>{w}s}'}\n",
    "\n",
    "def table_formatter(val, is_title=False, col_width=12, formats=None):\n",
    "    formats = formats or default_table_formats\n",
    "    type_ = lambda val: float if isinstance(val, (float, np.float)) else type(val)\n",
    "    return (formats['title'] if is_title else formats.get(type_(val), formats['default'])).format(val, w=col_width)\n",
    "\n",
    "every = lambda n, col: (lambda data: data[col] % n == 0)\n",
    "\n",
    "class Table():\n",
    "    def __init__(self, keys=None, report=(lambda data: True), formatter=table_formatter):\n",
    "        self.keys, self.report, self.formatter = keys, report, formatter\n",
    "        self.log = []\n",
    "        \n",
    "    def append(self, data):\n",
    "        self.log.append(data)\n",
    "        data = {' '.join(p): v for p,v in path_iter(data)}\n",
    "        self.keys = self.keys or data.keys()\n",
    "        if len(self.log) is 1:\n",
    "            print(*(self.formatter(k, True) for k in self.keys))\n",
    "        if self.report(data):\n",
    "            print(*(self.formatter(data[k]) for k in self.keys))\n",
    "            \n",
    "    def df(self):\n",
    "        return pd.DataFrame([{'_'.join(p): v for p,v in path_iter(row)} for row in self.log])     \n",
    "            \n",
    "def reduce(batches, state, steps):\n",
    "    #state: is a dictionary\n",
    "    #steps: are functions that take (batch, state)\n",
    "    #and return a dictionary of updates to the state (or None)\n",
    "    \n",
    "    for batch in chain(batches, [None]): \n",
    "    #we send an extra batch=None at the end for steps that \n",
    "    #need to do some tidying-up (e.g. log_activations)\n",
    "        for step in steps:\n",
    "            updates = step(batch, state)\n",
    "            if updates:\n",
    "                for k,v in updates.items():\n",
    "                    state[k] = v                  \n",
    "    return state\n",
    "  \n",
    "#define keys in the state dict as constants\n",
    "MODEL = 'model'\n",
    "VALID_MODEL = 'valid_model'\n",
    "OUTPUT = 'output'\n",
    "OPTS = 'optimisers'\n",
    "ACT_LOG = 'activation_log'\n",
    "WEIGHT_LOG = 'weight_log'\n",
    "\n",
    "#step definitions\n",
    "def forward(training_mode):\n",
    "    def step(batch, state):\n",
    "        if not batch: return\n",
    "        model = state[MODEL] if training_mode or (VALID_MODEL not in state) else state[VALID_MODEL]\n",
    "        if model.training != training_mode: #without the guard it's slow!\n",
    "            model.train(training_mode)\n",
    "        return {OUTPUT: model.loss(model(batch))}\n",
    "    return step\n",
    "\n",
    "def forward_tta(tta_transforms):\n",
    "    def step(batch, state):\n",
    "        if not batch: return\n",
    "        model = state[MODEL] if (VALID_MODEL not in state) else state[VALID_MODEL]\n",
    "        if model.training:\n",
    "            model.train(False)\n",
    "        logits = torch.mean(torch.stack([model({'input': transform(batch['input'].clone())})['logits'].detach() for transform in tta_transforms], dim=0), dim=0)\n",
    "        return {OUTPUT: model.loss(dict(batch, logits=logits))}\n",
    "    return step\n",
    "\n",
    "def backward(dtype=torch.float16):\n",
    "    def step(batch, state):\n",
    "        state[MODEL].zero_grad()\n",
    "        if not batch: return\n",
    "        state[OUTPUT]['loss'].to(dtype).sum().backward()\n",
    "    return step\n",
    "\n",
    "def opt_steps(batch, state):\n",
    "    if not batch: return\n",
    "    return {OPTS: [opt_step(**opt) for opt in state[OPTS]]}\n",
    "\n",
    "def log_activations(node_names=('loss', 'acc')):\n",
    "    logs = []\n",
    "    def step(batch, state):\n",
    "        if batch:\n",
    "            logs.extend((k, state[OUTPUT][k].detach()) for k in node_names)\n",
    "        else:\n",
    "            res = map_values((lambda xs: to_numpy(torch.cat(xs)).astype(np.float)), group_by_key(logs))\n",
    "            logs.clear()\n",
    "            return {ACT_LOG: res}\n",
    "    return step\n",
    "\n",
    "def update_ema(momentum, update_freq=1):\n",
    "    n = iter(count())\n",
    "    rho = momentum**update_freq\n",
    "    def step(batch, state):\n",
    "        if not batch: return\n",
    "        if (next(n) % update_freq) != 0: return\n",
    "        for v, ema_v in zip(state[MODEL].state_dict().values(), state[VALID_MODEL].state_dict().values()):\n",
    "            ema_v *= rho\n",
    "            ema_v += (1-rho)*v\n",
    "    return step\n",
    "\n",
    "train_steps = (forward(training_mode=True), log_activations(('loss', 'acc')), backward(), opt_steps)\n",
    "valid_steps = (forward(training_mode=False), log_activations(('loss', 'acc')))\n",
    "\n",
    "epoch_stats = lambda state: {k: np.mean(v) for k, v in state[ACT_LOG].items()}\n",
    "\n",
    "def train_epoch(state, timer, train_batches, valid_batches, train_steps=train_steps, valid_steps=valid_steps, on_epoch_end=identity):\n",
    "    train_summary, train_time = epoch_stats(on_epoch_end(reduce(train_batches, state, train_steps))), timer()\n",
    "    valid_summary, valid_time = epoch_stats(reduce(valid_batches, state, valid_steps)), timer(update_total=False) #DAWNBench rules\n",
    "    return {\n",
    "        'train': union({'time': train_time}, train_summary), \n",
    "        'valid': union({'time': valid_time}, valid_summary), \n",
    "        'total time': timer.total_time\n",
    "    }\n",
    "\n",
    "summary = lambda logs, cols=['valid_acc']: logs.df().query('epoch==epoch.max()')[cols].describe().transpose().astype({'count': int})[\n",
    "    ['count', 'mean', 'min', 'max', 'std']]\n",
    "\n",
    "#on_epoch_end\n",
    "def log_weights(state, weights):\n",
    "    state[WEIGHT_LOG] = state.get(WEIGHT_LOG, [])\n",
    "    state[WEIGHT_LOG].append({k: to_numpy(v.data) for k,v in weights.items()})\n",
    "    return state\n",
    "\n",
    "def fine_tune_bn_stats(state, batches, model_key=VALID_MODEL):\n",
    "    reduce(batches, {MODEL: state[model_key]}, [forward(True)])\n",
    "    return state\n",
    "\n",
    "#misc\n",
    "def warmup_cudnn(model, batch):\n",
    "    #run forward and backward pass of the model\n",
    "    #to allow benchmarking of cudnn kernels \n",
    "    reduce([batch], {MODEL: model}, [forward(True), backward()])\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "#####################\n",
    "## Plotting\n",
    "#####################\n",
    "\n",
    "import altair as alt\n",
    "alt.renderers.enable('colab')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import SVG\n",
    "\n",
    "def empty_plot(ax, **kw):\n",
    "    ax.axis('off')\n",
    "    return ax\n",
    "\n",
    "def image_plot(ax, img, title):\n",
    "    ax.imshow(to_numpy(unnormalise(transpose(img, 'CHW', 'HWC'))).astype(np.int))\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "\n",
    "def layout(figures, sharex=False, sharey=False, figure_title=None, col_width=4, row_height = 3.25, **kw):\n",
    "    nrows, ncols = np.array(figures).shape\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey, figsize=(col_width*ncols, row_height*nrows))\n",
    "    axs = [figure(ax, **kw) for row in zip(np.array(axs).reshape(nrows, ncols), figures) for ax, figure in zip(*row)]\n",
    "    fig.suptitle(figure_title)\n",
    "    return fig, axs\n",
    "\n",
    "#####################\n",
    "## Network\n",
    "#####################\n",
    "\n",
    "conv_block = lambda c_in, c_out: {\n",
    "    'conv': conv(in_channels=c_in, out_channels=c_out, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), \n",
    "    'norm': batch_norm(c_out), \n",
    "    'act':  relu(),\n",
    "}\n",
    "\n",
    "conv_pool_block = lambda c_in, c_out: dict(conv_block(c_in, c_out), pool=pool(2))\n",
    "conv_pool_block_pre = lambda c_in, c_out: reorder(conv_pool_block(c_in, c_out), ('conv', 'pool', 'norm', 'act'))\n",
    "\n",
    "residual = lambda c, conv_block: {\n",
    "    'in': (Identity, {}),\n",
    "    'res1': conv_block(c, c),\n",
    "    'res2': conv_block(c, c),\n",
    "    'out': (Identity, {}),\n",
    "    'add': (Add, {}, ['in', 'out']),\n",
    "}\n",
    "\n",
    "def build_network(channels, extra_layers, res_layers, scale, conv_block=conv_block, \n",
    "                  prep_block=conv_block, conv_pool_block=conv_pool_block, types=None): \n",
    "    net = {\n",
    "        'prep': prep_block(3, channels['prep']),\n",
    "        'layer1': conv_pool_block(channels['prep'], channels['layer1']),\n",
    "        'layer2': conv_pool_block(channels['layer1'], channels['layer2']),\n",
    "        'layer3': conv_pool_block(channels['layer2'], channels['layer3']),\n",
    "        'pool': pool(4),\n",
    "        'classifier': {\n",
    "            'flatten': (Flatten, {}),\n",
    "            'conv': linear(channels['layer3'], 10, bias=False),\n",
    "            'scale': (Mul, {'weight': scale}),\n",
    "        },\n",
    "        'logits': (Identity, {}),\n",
    "    }\n",
    "    for layer in res_layers:\n",
    "        net[layer]['residual'] = residual(channels[layer], conv_block)\n",
    "    for layer in extra_layers:\n",
    "        net[layer]['extra'] = conv_block(channels[layer], channels[layer])     \n",
    "    if types: net = map_types(types, net)\n",
    "    return net\n",
    "\n",
    "channels={'prep': 64, 'layer1': 128, 'layer2': 256, 'layer3': 512}\n",
    "network = partial(build_network, channels=channels, extra_layers=(), res_layers=('layer1', 'layer3'), scale=1/8)   \n",
    "\n",
    "x_ent_loss = Network({\n",
    "  'loss':  (nn.CrossEntropyLoss, {'reduction': 'none'}, ['logits', 'target']),\n",
    "  'acc': (Correct, {}, ['logits', 'target'])\n",
    "})\n",
    "\n",
    "label_smoothing_loss = lambda alpha: Network({\n",
    "        'logprobs': (LogSoftmax, {'dim': 1}, ['logits']),\n",
    "        'KL':  (KLLoss, {}, ['logprobs']),\n",
    "        'xent':  (CrossEntropyLoss, {}, ['logprobs', 'target']),\n",
    "        'loss': (AddWeighted, {'wx': 1-alpha, 'wy': alpha}, ['xent', 'KL']),\n",
    "        'acc': (Correct, {}, ['logits', 'target']),\n",
    "    })\n",
    "\n",
    "#####################\n",
    "## Misc\n",
    "#####################\n",
    "\n",
    "lr_schedule = lambda knots, vals, batch_size: PiecewiseLinear(np.array(knots)*len(train_batches(batch_size)), np.array(vals)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "qal6cf-W4llH"
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "## Config\n",
    "#####################\n",
    "\n",
    "N_RUNS = 1 #number of times to run each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "KZKTaJN94tnL"
   },
   "outputs": [],
   "source": [
    "!git clone -q https://github.com/davidcpage/cifar10-fast.git\n",
    "!cd cifar10-fast && python -m dawn --data_dir=~/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "7S23YXMQ45AY"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_images(dataset, n_images, samples_per_image):\n",
    "    output = np.zeros((32 * n_images, 32 * samples_per_image, 3))\n",
    "\n",
    "    row = 0\n",
    "    for images in dataset.repeat(samples_per_image).batch(n_images):\n",
    "        output[:, row*32:(row+1)*32] = np.vstack(images.numpy())\n",
    "        row += 1\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(output)\n",
    "    plt.show()\n",
    "\n",
    "def flip(x: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"Flip augmentation\n",
    "\n",
    "    Args:\n",
    "        x: Image to flip\n",
    "\n",
    "    Returns:\n",
    "        Augmented image\n",
    "    \"\"\"\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    x = tf.image.random_flip_up_down(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def color(x: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"Color augmentation\n",
    "\n",
    "    Args:\n",
    "        x: Image\n",
    "\n",
    "    Returns:\n",
    "        Augmented image\n",
    "    \"\"\"\n",
    "    x = tf.image.random_hue(x, 0.08)\n",
    "    x = tf.image.random_saturation(x, 0.6, 1.6)\n",
    "    x = tf.image.random_brightness(x, 0.05)\n",
    "    x = tf.image.random_contrast(x, 0.7, 1.3)\n",
    "    return x\n",
    "\n",
    "def rotate(x: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"Rotation augmentation\n",
    "\n",
    "    Args:\n",
    "        x: Image\n",
    "\n",
    "    Returns:\n",
    "        Augmented image\n",
    "    \"\"\"\n",
    "\n",
    "    return tf.image.rot90(x, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
    "\n",
    "def zoom(x: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"Zoom augmentation\n",
    "\n",
    "    Args:\n",
    "        x: Image\n",
    "\n",
    "    Returns:\n",
    "        Augmented image\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate 20 crop settings, ranging from a 1% to 20% crop.\n",
    "    scales = list(np.arange(0.8, 1.0, 0.01))\n",
    "    boxes = np.zeros((len(scales), 4))\n",
    "\n",
    "    for i, scale in enumerate(scales):\n",
    "        x1 = y1 = 0.5 - (0.5 * scale)\n",
    "        x2 = y2 = 0.5 + (0.5 * scale)\n",
    "        boxes[i] = [x1, y1, x2, y2]\n",
    "\n",
    "    def random_crop(img):\n",
    "        # Create different crops for an image\n",
    "        crops = tf.image.crop_and_resize([img], boxes=boxes, box_indices=np.zeros(len(scales)), crop_size=(32, 32))\n",
    "        # Return a random crop\n",
    "        return crops[tf.random.uniform(shape=[], minval=0, maxval=len(scales), dtype=tf.int32)]\n",
    "\n",
    "\n",
    "    choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
    "\n",
    "    # Only apply cropping 50% of the time\n",
    "    return tf.cond(choice < 0.5, lambda: x, lambda: random_crop(x))\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "data = (x_train[0:8] / 255).astype(np.float32)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "\n",
    "# Add augmentations\n",
    "augmentations = [flip, color, zoom, rotate]\n",
    "\n",
    "for f in augmentations:\n",
    "    dataset = dataset.map(lambda x: tf.cond(tf.random.uniform([], 0, 1) > 0.75, lambda: f(x), lambda: x), num_parallel_calls=4)\n",
    "dataset = dataset.map(lambda x: tf.clip_by_value(x, 0, 1))\n",
    "\n",
    "plot_images(dataset, n_images=8, samples_per_image=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "C_6-PjGplQhl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ynwzGIAneBbb",
    "nNMAg7s3W0gg",
    "XFrH0OVORco2",
    "waS75-jNaEL1",
    "UlrSyMQpoV9f",
    "-3bIU8BErhiJ",
    "qDy7DsTiSBXp"
   ],
   "name": "ResNet9",
   "private_outputs": true,
   "provenance": {
    "file_id": [
     "https://github.com/khipu-ai/practicals-2019/blob/master/1a_conv_nets.ipynb",
     "timestamp",
     1590696984024
    ]
   }
  },
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  },
  "name": "ResNet9.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
